<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Performance Tips · GraphTensorNetworks.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="https://QuEraComputing.github.io/GraphTensorNetworks.jl/performancetips/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/indigo.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">GraphTensorNetworks.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Problems</span><ul><li><a class="tocitem" href="../tutorials/IndependentSet/">Independent set problem</a></li><li><a class="tocitem" href="../tutorials/MaximalIS/">Maximal independent set problem</a></li><li><a class="tocitem" href="../tutorials/MaxCut/">Cutting problem</a></li><li><a class="tocitem" href="../tutorials/Matching/">Vertex Matching problem</a></li><li><a class="tocitem" href="../tutorials/PaintShop/">Binary paint shop problem</a></li><li><a class="tocitem" href="../tutorials/Coloring/">Coloring problem</a></li><li><a class="tocitem" href="../tutorials/DominatingSet/">Dominating set problem</a></li><li><a class="tocitem" href="../tutorials/Satisfiability/">Satisfiability problem</a></li><li><a class="tocitem" href="../tutorials/SetCovering/">Set covering problem</a></li><li><a class="tocitem" href="../tutorials/SetPacking/">Set packing problem</a></li></ul></li><li><span class="tocitem">Topics</span><ul><li><a class="tocitem" href="../tutorials/saveload/">Save and load solutions</a></li><li><a class="tocitem" href="../tutorials/weighted/">Weighted problems</a></li><li><a class="tocitem" href="../tutorials/open/">Open degree of freedoms</a></li></ul></li><li class="is-active"><a class="tocitem" href>Performance Tips</a><ul class="internal"><li><a class="tocitem" href="#Optimize-tensor-network-contraction-orders"><span>Optimize tensor network contraction orders</span></a></li><li><a class="tocitem" href="#Slicing"><span>Slicing</span></a></li><li><a class="tocitem" href="#GEMM-for-Tropical-numbers"><span>GEMM for Tropical numbers</span></a></li><li><a class="tocitem" href="#Sum-product-representation-for-configurations"><span>Sum product representation for configurations</span></a></li><li><a class="tocitem" href="#Multiprocessing"><span>Multiprocessing</span></a></li><li><a class="tocitem" href="#Make-use-of-GPUs"><span>Make use of GPUs</span></a></li></ul></li><li><a class="tocitem" href="../ref/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Performance Tips</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Performance Tips</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/QuEraComputing/GraphTensorNetworks.jl/blob/master/docs/src/performancetips.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Performance-Tips"><a class="docs-heading-anchor" href="#Performance-Tips">Performance Tips</a><a id="Performance-Tips-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-Tips" title="Permalink"></a></h1><h2 id="Optimize-tensor-network-contraction-orders"><a class="docs-heading-anchor" href="#Optimize-tensor-network-contraction-orders">Optimize tensor network contraction orders</a><a id="Optimize-tensor-network-contraction-orders-1"></a><a class="docs-heading-anchor-permalink" href="#Optimize-tensor-network-contraction-orders" title="Permalink"></a></h2><pre><code class="language-julia hljs">julia&gt; using GraphTensorNetworks, Graphs, Random

julia&gt; graph = random_regular_graph(120, 3)
{120, 180} undirected simple Int64 graph

julia&gt; problem = IndependentSet(graph; optimizer=TreeSA(
    sc_target=20, sc_weight=1.0, rw_weight=3.0, ntrials=10, βs=0.01:0.1:15.0, niters=20), simplifier=MergeGreedy());</code></pre><p>Key word argument <code>optimizer</code> decides the contraction order optimizer of the tensor network. Here, we choose the <code>TreeSA</code> optimizer to optimize the tensor network contraciton tree, it is a local search based algorithm. It is one of the state of the art tensor network contraction order optimizers, one may check <a href="https://arxiv.org/abs/2108.05665">arXiv: 2108.05665</a> to learn more about the algorithm. Other optimizers include</p><ul><li><a href="../ref/#OMEinsumContractionOrders.GreedyMethod"><code>GreedyMethod</code></a> (default, fastest in searching speed but worst in contraction complexity)</li><li><a href="../ref/#OMEinsumContractionOrders.TreeSA"><code>TreeSA</code></a> (often best in contraction complexity, supports slicing)</li><li><a href="../ref/#OMEinsumContractionOrders.KaHyParBipartite"><code>KaHyParBipartite</code></a></li><li><a href="../ref/#OMEinsumContractionOrders.SABipartite"><code>SABipartite</code></a></li></ul><p>One can type <code>?TreeSA</code> in a Julia REPL for more information about how to configure the hyper-parameters of <code>TreeSA</code> method. <code>simplifier</code> keyword argument is not so important, it is a preprocessing routine to improve the searching speed of the <code>optimizer</code>.</p><p>The returned instance <code>problem</code> contains a field <code>code</code> that specifies the tensor network contraction order. For an independent set problem, its contraction time space complexity is <span>$2^{{\rm tw}(G)}$</span>, where <span>${\rm tw(G)}$</span> is the <a href="https://en.wikipedia.org/wiki/Treewidth">tree-width</a> of <span>$G$</span>. One can check the time, space and read-write complexity with the following function.</p><pre><code class="language-julia hljs">julia&gt; timespacereadwrite_complexity(problem)
(21.90683335864693, 17.0, 20.03588509836998)</code></pre><p>The return values are <code>log2</code> of the the number of iterations, the number elements in the largest tensor during contraction and the number of read-write operations to tensor elements. In this example, the number of <code>+</code> and <code>*</code> operations are both <span>$\sim 2^{21.9}$</span> and the number of read-write operations are <span>$\sim 2^{20}$</span>. The largest tensor size is <span>$2^17$</span>, one can check the element size by typing</p><pre><code class="language-julia hljs">julia&gt; sizeof(TropicalF64)
8

julia&gt; sizeof(TropicalF32)
4

julia&gt; sizeof(StaticBitVector{200,4})
32

julia&gt; sizeof(TruncatedPoly{5,Float64,Float64})
48</code></pre><p>One can use <a href="../ref/#GraphTensorNetworks.estimate_memory"><code>estimate_memory</code></a> to get a good estimation of peak memory in bytes.</p><pre><code class="language-julia hljs">julia&gt; estimate_memory(problem, GraphPolynomial(; method=:finitefield))
297616

julia&gt; estimate_memory(problem, GraphPolynomial(; method=:polynomial))
71427840</code></pre><p>It means one only needs 298 KB memory to find the graph polynomial with the finite field approach, but needs 71 MB memory to find the graph polynomial using the <a href="https://juliamath.github.io/Polynomials.jl/stable/polynomials/polynomial/#Polynomial-2"><code>Polynomial</code></a> type.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><ul><li>The actual run time memory can be several times larger than the size of the maximum tensor.</li></ul><p>There is no constant bound for the factor, an empirical value for it is 3x.</p><ul><li>For mutable types like <a href="https://juliamath.github.io/Polynomials.jl/stable/polynomials/polynomial/#Polynomial-2"><code>Polynomial</code></a> and <a href="../ref/#GraphTensorNetworks.ConfigEnumerator"><code>ConfigEnumerator</code></a>, the <code>sizeof</code> function does not measure the actual element size.</li></ul></div></div><h2 id="Slicing"><a class="docs-heading-anchor" href="#Slicing">Slicing</a><a id="Slicing-1"></a><a class="docs-heading-anchor-permalink" href="#Slicing" title="Permalink"></a></h2><p>For large scale applications, it is also possible to slice over certain degrees of freedom to reduce the space complexity, i.e. loop and accumulate over certain degrees of freedom so that one can have a smaller tensor network inside the loop due to the removal of these degrees of freedom. In the <a href="../ref/#OMEinsumContractionOrders.TreeSA"><code>TreeSA</code></a> optimizer, one can set <code>nslices</code> to a value larger than zero to turn on this feature.</p><pre><code class="language-julia hljs">julia&gt; using GraphTensorNetworks, Graphs, Random

julia&gt; graph = random_regular_graph(120, 3)
{120, 180} undirected simple Int64 graph

julia&gt; problem = IndependentSet(graph; optimizer=TreeSA(βs=0.01:0.1:25.0, ntrials=10, niters=10));

julia&gt; timespacereadwrite_complexity(problem)
(20.856518235241687, 16.0, 18.88208476145812)

julia&gt; problem = IndependentSet(graph; optimizer=TreeSA(βs=0.01:0.1:25.0, ntrials=10, niters=10, nslices=5));

julia&gt; timespacereadwrite_complexity(problem)
(21.134967710592804, 11.0, 19.84529401927876)</code></pre><p>In the second <code>IndependentSet</code> constructor, we slice over 5 degrees of freedom, which can reduce the space complexity by at most 5. In this application, the slicing achieves the largest possible space complexity reduction 5, while the time and read-write complexity are only increased by less than 1, i.e. the peak memory usage is reduced by a factor <span>$32$</span>, while the (theoretical) computing time is increased by at a factor <span>$&lt; 2$</span>.</p><h2 id="GEMM-for-Tropical-numbers"><a class="docs-heading-anchor" href="#GEMM-for-Tropical-numbers">GEMM for Tropical numbers</a><a id="GEMM-for-Tropical-numbers-1"></a><a class="docs-heading-anchor-permalink" href="#GEMM-for-Tropical-numbers" title="Permalink"></a></h2><p>You can speed up the Tropical number matrix multiplication when computing <code>SizeMax()</code> by using the Tropical GEMM routines implemented in package <a href="https://github.com/TensorBFS/TropicalGEMM.jl/"><code>TropicalGEMM.jl</code></a>.</p><pre><code class="language-julia hljs">julia&gt; using BenchmarkTools

julia&gt; @btime solve(problem, SizeMax())
  91.630 ms (19203 allocations: 23.72 MiB)
0-dimensional Array{TropicalF64, 0}:
53.0ₜ

julia&gt; using TropicalGEMM

julia&gt; @btime solve(problem, SizeMax())
  8.960 ms (18532 allocations: 17.01 MiB)
0-dimensional Array{TropicalF64, 0}:
53.0ₜ</code></pre><p>The <code>TropicalGEMM</code> pirates the <code>LinearAlgebra.mul!</code> interface, hence it takes effect upon using. The GEMM routine can speed up the computation on CPU for one order, with multi-threading, it can be even faster. Benchmark shows the performance of <code>TropicalGEMM</code> is close to the theoretical optimal value.</p><h2 id="Sum-product-representation-for-configurations"><a class="docs-heading-anchor" href="#Sum-product-representation-for-configurations">Sum product representation for configurations</a><a id="Sum-product-representation-for-configurations-1"></a><a class="docs-heading-anchor-permalink" href="#Sum-product-representation-for-configurations" title="Permalink"></a></h2><p><a href="../ref/#GraphTensorNetworks.SumProductTree"><code>SumProductTree</code></a> (an alias of <a href="../ref/#GraphTensorNetworks.SumProductTree"><code>SumProductTree</code></a> with <a href="../ref/#GraphTensorNetworks.StaticElementVector"><code>StaticElementVector</code></a> as its data type) can save a lot memory for you to store exponential number of configurations in polynomial space. It is a sum-product expression tree to store <a href="../ref/#GraphTensorNetworks.ConfigEnumerator"><code>ConfigEnumerator</code></a> in a lazy style, configurations can be extracted by depth first searching the tree with the <code>Base.collect</code> method. Although it is space efficient, it is in general not easy to extract information from it. This tree structure supports directed sampling so that one can get some statistic properties from it with an intermediate effort.</p><p>For example, if we want to check some property of an intermediate scale graph, one can type</p><pre><code class="language-julia hljs">julia&gt; graph = random_regular_graph(70, 3)

julia&gt; problem = IndependentSet(graph; optimizer=TreeSA());

julia&gt; tree = solve(problem, ConfigsAll(; tree_storage=true))[];
16633909006371</code></pre><p>If one wants to store these configurations, he will need a hard disk of size 256 TB! However, this sum-product binary tree structure supports efficient and unbiased direct sampling.</p><pre><code class="language-julia hljs">samples = generate_samples(tree, 1000);</code></pre><p>With these samples, one can already compute useful properties like distribution of hamming distance (see <a href="../ref/#GraphTensorNetworks.hamming_distribution"><code>hamming_distribution</code></a>).</p><pre><code class="language-julia hljs">julia&gt; using UnicodePlots

julia&gt; lineplot(hamming_distribution(samples, samples))
          ┌────────────────────────────────────────┐ 
   100000 │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢰⠹⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
          │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡎⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
          │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⡇⠀⢣⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
          │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⠀⠀⢸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
          │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⠀⠀⠸⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
          │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⠀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
          │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⠀⠀⣇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
          │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢰⠃⠀⠀⠀⢸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
          │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⠀⠀⠀⠀⢸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
          │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡞⠀⠀⠀⠀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
          │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⠀⠀⠀⠀⣇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
          │⠀⠀⠀⠀⠀⠀⠀⠀⠀⢰⠁⠀⠀⠀⠀⠀⢸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
          │⠀⠀⠀⠀⠀⠀⠀⠀⠀⡼⠀⠀⠀⠀⠀⠀⠈⡆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
          │⠀⠀⠀⠀⠀⠀⠀⠀⢠⠇⠀⠀⠀⠀⠀⠀⠀⢳⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
        0 │⢀⣀⣀⣀⣀⣀⣀⣀⠎⠀⠀⠀⠀⠀⠀⠀⠀⠀⠓⢄⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⠀⠀⠀⠀│ 
          └────────────────────────────────────────┘ 
          ⠀0⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀80⠀ </code></pre><h2 id="Multiprocessing"><a class="docs-heading-anchor" href="#Multiprocessing">Multiprocessing</a><a id="Multiprocessing-1"></a><a class="docs-heading-anchor-permalink" href="#Multiprocessing" title="Permalink"></a></h2><p>Submodule <code>GraphTensorNetworks.SimpleMutiprocessing</code> provides a function <a href="../ref/#GraphTensorNetworks.SimpleMultiprocessing.multiprocess_run"><code>GraphTensorNetworks.SimpleMultiprocessing.multiprocess_run</code></a> function for simple multi-processing jobs. Suppose we want to find the independence polynomial for multiple graphs with 4 processes. We can create a file, e.g. named <code>run.jl</code> with the following content</p><pre><code class="language-julia hljs">using Distributed, GraphTensorNetworks.SimpleMultiprocessing
using Random, GraphTensorNetworks  # to avoid multi-precompiling
@everywhere using Random, GraphTensorNetworks

results = multiprocess_run(collect(1:10)) do seed
    Random.seed!(seed)
    n = 10
    @info &quot;Graph size $n x $n, seed= $seed&quot;
    g = random_diagonal_coupled_graph(n, n, 0.8)
    gp = Independence(g; optimizer=TreeSA(), simplifier=MergeGreedy())
    res = solve(gp, GraphPolynomial())[]
    return res
end

println(results)</code></pre><p>One can run this script file with the following command</p><pre><code class="language-bash hljs">$ julia -p4 run.jl
      From worker 3:	[ Info: running argument 4 on device 3
      From worker 4:	[ Info: running argument 2 on device 4
      From worker 5:	[ Info: running argument 3 on device 5
      From worker 2:	[ Info: running argument 1 on device 2
      From worker 3:	[ Info: Graph size 10 x 10, seed= 4
      From worker 4:	[ Info: Graph size 10 x 10, seed= 2
      From worker 5:	[ Info: Graph size 10 x 10, seed= 3
      From worker 2:	[ Info: Graph size 10 x 10, seed= 1
      From worker 4:	[ Info: running argument 5 on device
      ...</code></pre><p>You will see a vector of polynomials printed out.</p><h2 id="Make-use-of-GPUs"><a class="docs-heading-anchor" href="#Make-use-of-GPUs">Make use of GPUs</a><a id="Make-use-of-GPUs-1"></a><a class="docs-heading-anchor-permalink" href="#Make-use-of-GPUs" title="Permalink"></a></h2><p>To upload the computing to GPU, you just add need to use CUDA, and offer a new key word argument.</p><pre><code class="language-julia hljs">julia&gt; using CUDA
[ Info: OMEinsum loaded the CUDA module successfully

julia&gt; solve(problem, SizeMax(), usecuda=true)
0-dimensional CuArray{TropicalF64, 0, CUDA.Mem.DeviceBuffer}:
53.0ₜ</code></pre><p>CUDA backended properties are</p><ul><li><a href="../ref/#GraphTensorNetworks.SizeMax"><code>SizeMax</code></a></li><li><a href="../ref/#GraphTensorNetworks.CountingAll"><code>CountingAll</code></a></li><li><a href="../ref/#GraphTensorNetworks.CountingMax"><code>CountingMax</code></a></li><li><a href="../ref/#GraphTensorNetworks.GraphPolynomial"><code>GraphPolynomial</code></a></li><li><a href="../ref/#GraphTensorNetworks.SingleConfigMax"><code>SingleConfigMax</code></a></li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../tutorials/open/">« Open degree of freedoms</a><a class="docs-footer-nextpage" href="../ref/">References »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.15 on <span class="colophon-date" title="Sunday 10 April 2022 02:22">Sunday 10 April 2022</span>. Using Julia version 1.7.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
